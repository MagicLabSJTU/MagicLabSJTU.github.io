---

# 论文完整标题

title: 'Measure and Countermeasure of the Capsulation Attack against Backdoor-based Deep Neural Network Watermarks'

# 论文作者，此处仅需填写本实验室成员（包括王老师）即可，使用中文姓名

authors:

- 李方圻
- 王士林

# 论文发表时间，年-月-日，大致即可

date: '2023-06-06'

# 论文类型， 可选：conference, journal

publication_types: ['conference']

# 会议/期刊名称及缩写

publication: In *IEEE International Conference on Acoustics, Speech and Signal Processing 2023*
publication_short: In *ICASSP 2023*

# 论文摘要，不要有换行

abstract: Backdoor-based watermarking schemes were proposed to protect the intellectual property of deep neural networks under the black-box setting. However, additional security risks emerge after the schemes have been published for as forensics tools. This paper reveals the capsulation attack that can easily invalidate most established backdoor-based watermarking schemes without sacrificing the pirated model's functionality. By encapsulating the deep neural network with a filter, an adversary can block abnormal queries and reject the ownership verification. We propose a metric to measure a backdoor-based watermarking scheme's security against the capsulation attack, and design a new backdoor-based deep neural network watermarking scheme that is secure against the capsulation attack by inverting the encoding process.

# 后续内容无需修改

url_pdf: ''
---