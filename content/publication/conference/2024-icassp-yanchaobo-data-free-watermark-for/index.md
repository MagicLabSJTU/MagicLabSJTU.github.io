---
# 论文完整标题
title: 'Data-Free Watermark for Deep Neural Networks by Truncated Adversarial Distillation'

# 论文作者，此处仅需填写本实验室成员（包括王老师）即可，使用中文姓名
authors:
  - 闫超博
  - 李方圻
  - 王士林

# 论文发表时间，年-月-日，大致即可
date: '2024-03-01'

# 论文类型， 可选：conference, journal
publication_types: ['conference']

# 会议/期刊名称及缩写
publication: In *IEEE International Conference on Acoustics, Speech and Signal Processing 2024*
publication_short: In *ICASSP 2024*

# 论文摘要，不要有换行
abstract: Model watermarking secures ownership verification and copyright protection of deep neural networks. In the black-box scenario, watermarking schemes commonly rely on injecting triggers and requiring the model's training data to maintain its performance. However, such knowledge might be unavailable in commercial settings as model transactions or copyright transfers. To tackle this challenge, we propose a novel data-free black-box watermarking scheme. Our approach modifies data-free adversarial distillation to efficiently obtain a generator that produces samples serving as a substitute for the training data so the watermark can achieve high fidelity without referring to the training data.

# 后续内容无需修改
url_pdf: ''
---